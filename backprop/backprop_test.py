#
# laods MLP, with one hidden layer (784-512-10)
#
# attempts to compute gradient of parameters using backprop manually
#

import torch
import torch.nn as nn
import torch.nn.functional as F

image_7 = b"\
\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\
\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\
\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\
\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\
\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\
\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\
\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\
\x00\x00\x00\x00\x00\x00\x54\xb9\x9f\x97\x3c\x24\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\
\x00\x00\x00\x00\x00\x00\xde\xfe\xfe\xfe\xfe\xf1\xc6\xc6\xc6\xc6\xc6\xc6\xc6\xc6\xaa\x34\x00\x00\x00\x00\x00\x00\
\x00\x00\x00\x00\x00\x00\x43\x72\x48\x72\xa3\xe3\xfe\xe1\xfe\xfe\xfe\xfa\xe5\xfe\xfe\x8c\x00\x00\x00\x00\x00\x00\
\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x11\x42\x0e\x43\x43\x43\x3b\x15\xec\xfe\x6a\x00\x00\x00\x00\x00\x00\
\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x53\xfd\xd1\x12\x00\x00\x00\x00\x00\x00\
\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x16\xe9\xff\x53\x00\x00\x00\x00\x00\x00\x00\
\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x81\xfe\xee\x2c\x00\x00\x00\x00\x00\x00\x00\
\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x3b\xf9\xfe\x3e\x00\x00\x00\x00\x00\x00\x00\x00\
\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x85\xfe\xbb\x05\x00\x00\x00\x00\x00\x00\x00\x00\
\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x09\xcd\xf8\x3a\x00\x00\x00\x00\x00\x00\x00\x00\x00\
\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x7e\xfe\xb6\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\
\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x4b\xfb\xf0\x39\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\
\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x13\xdd\xfe\xa6\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\
\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x03\xcb\xfe\xdb\x23\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\
\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x26\xfe\xfe\x4d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\
\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x1f\xe0\xfe\x73\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\
\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x85\xfe\xfe\x34\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\
\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x3d\xf2\xfe\xfe\x34\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\
\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x79\xfe\xfe\xdb\x28\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\
\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x79\xfe\xcf\x12\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\
\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\
"

def one_hot(klass, num_classes=10):
    return [1.0 if klass == i else 0.0 for i in range(num_classes)]


class MNIST_Net(nn.Module):
    def __init__(self):
        super(MNIST_Net, self).__init__()
        self.fc1 = nn.Linear(28 * 28, 512)
        self.fc2 = nn.Linear(512, 10)

    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x



model = MNIST_Net()
state_dict = torch.load("model_state_dict.dat")  # from ../mnist
model.load_state_dict(state_dict)

criterion = nn.MSELoss()

# forward
target = torch.Tensor(one_hot(7))
x = torch.Tensor([float(byte) for byte in image_7])
result = model(x)
print(f"result = {result}")
print(f"target = {target}")
print(f"argmax(result) = {result.argmax()}")
print(f"argmax(target) = {target.argmax()}")

# backward
loss = criterion(result, target)
print(f"loss = {loss}")
loss.backward()

# print first parameters
print("parameters =")
for name, param in model.named_parameters():
    print(f"    {name}, size = {param.size()}")

    # print(f"        grad = {param.grad}")
    for i in range(10):
        print(f"        value[{i}] = {param[i]}")
        print(f"




print(f"fc1.weight = {state_dict['fc1.weight'].size()}")
print(f"fc1.bias = {state_dict['fc1.bias'].size()}")
print(f"fc2.weight = {state_dict['fc2.weight'].size()}")
print(f"fc2.bias = {state_dict['fc2.bias'].size()}")

# state_dict weights might be on the gpu, so move it to the cpu
fc1_weight = state_dict['fc1.weight'].cpu()
fc1_bias = state_dict['fc1.bias'].cpu()
fc2_weight = state_dict['fc2.weight'].cpu()
fc2_bias = state_dict['fc2.bias'].cpu()


def manual_model(x, state_dict):
    layer1 = F.relu(fc1_weight @ x + fc1_bias)
    layer2 = fc2_weight @ layer1 + fc2_bias
    return layer2


manual_result = manual_model(x, state_dict)
print(f"manual_result = {manual_result.argmax()}")


